1. What is the Big-O of the following algorithm:

def goodbye_world(n)
 puts "Goodbye World! #{n}"
end


This is a Constant time algorithm 0(1). It will always take the same amount of time to execute.
It prints "Goodbye world" with the addition of one 'n' input.

2. What's the Big-O of the following algorithm? Submit your work and reasoning with your solution.
def find_largest(collection)
 largest = collection[0]
 collection.length.times do |i|
   if collection[i] >= largest
     largest = collection[i]
   end
 end
 largest
end


In this case, the function first sets largest = collection[0] which is a constant time operation.
The second part of the function iterates over the collection to find the largest value.
In a worst case Big-0 scenario, this is a linear time complexity 0(n) with n being the number of
items in the collection.



3. What's the Big-O of the following algorithm? Submit your work and reasoning with your solution.
def find_largest(collection)
 largest = collection[0][0]
 collection.length.times do |i|
   subcollection = collection[i]
   subcollection.length.times do |j|
     if subcollection[j] >= largest
       largest = subcollection[j]
     end
   end
 end
 largest
end

Here we are looking to find the largest value in a 2D array, which is basically an array
that contains other arrays. First we set largest = collection[0][0] which is constant time operation.
Next we enter an iteration from the length of the collection.
While we execute this iteration,we iterate over the items in the subcollection for the the length of that subcollection.
The Big-O for this function is 0(n^2). We are taking the n length of the collection and multiplying it by the n length of the subcollection.


4.What's the Big-O of the following algorithm?
Submit your work and reasoning with your solution.

def numbers(n)
 if (n == 0)
   return 0
 elsif (n == 1)
   return 1
 else
   return numbers(n-1) + numbers(n-2)
 end
end

There are three scenarios here.
1. If n == 0, Big-O complexity is constant and the function returns 0.
2. If n==1, Big-O complexity is constant and the function returns 1.
3. If n is not zero or 1. For example if n = 4,
      We go to the 'else' conditional and recursive calls numbers(4-1) + numbers(4-2) is run.
      Numbers(3) + numbers(2) doesn't satisfy any criteria or finish the process.
          Recursion #1- Numbers(3) recursively breaks into numbers(2) + numbers(1) which results in numbers (2) + 1
              Recursion #1A- Numbers(2) becomes numbers(1) + numbers(0). This solves to 1 + 0 PLUS the 1 from Recursion 1.

This is the fibonacci sequence!

We can assume that the time it takes to process numbers(n-2) is just about the same as numbers(n-1).
2 * T(n-1)  = 2T(n-2) + constant
In the case of k = 4
2 x (2T(n-2) +c)  +c =  4T(n-4) + 3c

This breaks downs to 2^k * T(n-2k) + (2^k-1) * c
The largest time is the 2^k.


The Big-O complexity here is O(2^n)




5. What's the Big-O of the following algorithm?
Submit your work and reasoning with your solution.

def iterative(n)
 num1 = 0
 num2 = 1
 i = 0
 while i < n-1
   tmp = num1 + num2
   num1 = num2
   num2 = tmp
   i+=1
 end
 num2
 end

The Big 0 complexity of this algorithm is O(n).
In the case of n=100, for example, the while loop will
will run from i=0 until i = 99.



6.What's the Big-O of the following algorithm?
Submit your work and reasoning with your solution.


def sort(collection, from=0, to=nil)
 if to == nil
   # Sort the whole collection, by default
   to = collection.count - 1
 end

 if from >= to
   # Done sorting
   return
 end

 # Take a pivot value, at the far left
 pivot = collection[from]

 # Min and Max pointers
 min = from
 max = to

 # Current free slot
 free = min

 while min < max
   if free == min # Evaluate collection[max]
     if collection[max] <= pivot # Smaller than pivot, must move
       collection[free] = collection[max]
       min += 1
       free = max
     else
       max -= 1
     end
   elsif free == max # Evaluate collection[min]
     if collection[min] >= pivot # Bigger than pivot, must move
       collection[free] = collection[min]
       max -= 1
       free = min
     else
       min += 1
     end
   else
     raise "Inconsistent state"
   end
 end

 collection[free] = pivot

 sort collection, from, free - 1
 sort collection, free + 1, to

 collection
end

Big-O complexity for this type of quicksort algorithm is 0(n^2).
We have various variable assignments and if statements that run on constant time.
The most time consuming portion of the algorithm occurs in the recursive calls at the end.
This can happen when the partition process picks the greatest (or smallest) element in the collection as
the pivot. 
